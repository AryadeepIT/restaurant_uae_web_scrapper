{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import csv\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Base URL for restaurant listings\n",
        "BASE_URL = 'https://www.yellowpages-uae.com/uae/restaurant'\n",
        "\n",
        "# Function to extract business details from a given URL\n",
        "def extract_business_data(url):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    # List to store extracted business data\n",
        "    businesses = []\n",
        "\n",
        "    # Iterate over each business entry on the page\n",
        "    for business in soup.find_all('div', {'class': 'row box foc'}):\n",
        "        # Extract individual business details\n",
        "        name = business.find('h2', {'class': 'cmp_name'})\n",
        "        location = business.find('span', itemprop='streetAddress')\n",
        "        city = business.find('strong', itemprop='addressLocality')\n",
        "        po_box = business.find('span', itemprop='postalCode')\n",
        "\n",
        "        phone = business.find('span', itemprop='telephone')\n",
        "        phone_text = phone.text.strip() if phone else ''\n",
        "\n",
        "        mobiles = business.find_all('span', itemprop='telephone')\n",
        "        mobile_text = mobiles[1].text.strip() if len(mobiles) > 1 else ''\n",
        "\n",
        "        link = business.find('a')\n",
        "        logo = business.find('img', itemprop='image')\n",
        "\n",
        "        # Create a dictionary to store business data\n",
        "        business_data = {\n",
        "            'Name': name.text.strip() if name else '',\n",
        "            'Location': location.text.strip() if location else '',\n",
        "            'City': city.text.strip() if city else '',\n",
        "            'P.O Box': po_box.text.strip() if po_box else '',\n",
        "            'Phone': phone_text,\n",
        "            'Mobile': mobile_text,\n",
        "            'Company Page Link': BASE_URL + link['href'] if link else '',\n",
        "            'Logo URL': logo.get('data-src', '') if logo and 'data-src' in logo.attrs else ''\n",
        "        }\n",
        "\n",
        "        # Append the business data to the list\n",
        "        businesses.append(business_data)\n",
        "\n",
        "    return businesses\n",
        "\n",
        "# Function to scrape all pages of restaurant listings\n",
        "def scrape_all_pages(base_url):\n",
        "    all_businesses = []\n",
        "    page_number = 1\n",
        "\n",
        "    # Loop through each page to extract businesses\n",
        "    while True:\n",
        "        url = f'{base_url}-{page_number}.html'\n",
        "        businesses = extract_business_data(url)\n",
        "\n",
        "        # Break if no more businesses are found\n",
        "        if not businesses:\n",
        "            break\n",
        "\n",
        "        all_businesses.extend(businesses)\n",
        "        page_number += 1\n",
        "\n",
        "    return all_businesses\n",
        "\n",
        "# Function to save data to a CSV file\n",
        "def save_to_csv(data, filename='results.csv'):\n",
        "    with open(filename, 'w', newline='', encoding='utf-8') as file:\n",
        "        writer = csv.DictWriter(file, fieldnames=data[0].keys())\n",
        "        writer.writeheader()\n",
        "        writer.writerows(data)\n",
        "\n",
        "# Main execution\n",
        "if __name__ == '__main__':\n",
        "    all_businesses = scrape_all_pages(BASE_URL)\n",
        "    save_to_csv(all_businesses)\n",
        "\n",
        "    # Print the number of businesses scraped\n",
        "    print(f'Scraped businesses and saved to results.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ow6aySimrixO",
        "outputId": "70a3f23d-e97c-4631-fec0-cf160e475258"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraped businesses and saved to results.csv\n"
          ]
        }
      ]
    }
  ]
}